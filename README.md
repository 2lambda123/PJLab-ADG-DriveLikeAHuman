# Drive Like A Human
Drive Like a Human: Rethinking Autonomous Driving with Large Language Models

## Closed-loop interaction ability in driving scenarios

We conducted a closed-loop driving experiment on [HighwayEnv](https://github.com/Farama-Foundation/HighwayEnv) using GPT-3.5 to verify LLM’s interpretation and environmental interaction abilities. As a text-only large language model, GPT-3.5 cannot directly interact with HighwayEnv, so we provided perception tools and agent prompts to aid its observation and decision-making. The Agent Prompts provide GPT-3.5 with information about its current actions, driving rules, and cautions, while Perception Tools parse observations generated by HighwayEnv to help GPT-3.5 understand the current scenario. Based on this information, GPT-3.5 makes decisions and controls the vehicles in HighwayEnv, forming a closed-loop driving system. 

![img](assets/closeLoop.png)

Running `HELLM.py` allows you to experience LLM’s closed-loop driving in HighwayEnv. First, you need to modify config.yaml to configure your LLM.

```yaml
OPENAI_API_TYPE: 'azure' #'azure'  OR 'openai'
# for 'openai'
OPENAI_KEY: 'sk-xxxxxxxxxxx' # your openai key
# for 'azure'
AZURE_MODEL: 'XXXXX' # your deploment_model_name 
AZURE_API_BASE: https://xxxxxxxx.openai.azure.com/ # your deployment endpoint
AZURE_API_KEY: 'xxxxxx' # your deployment key
AZURE_API_VERSION: '2023-03-15-preview'
```

We use GPT-3.5 as the default LLM, but you can also refer to [LangChain-Large Language Models](https://python.langchain.com/docs/modules/model_io/models/) to define your own LLM. In this case, you need to modify lines 20-40 of `HELLM.py` to configure your own LLM.

```Python
OPENAI_CONFIG = yaml.load(open('config.yaml'), Loader=yaml.FullLoader)

if OPENAI_CONFIG['OPENAI_API_TYPE'] == 'azure':
    os.environ["OPENAI_API_TYPE"] = OPENAI_CONFIG['OPENAI_API_TYPE']
    os.environ["OPENAI_API_VERSION"] = OPENAI_CONFIG['AZURE_API_VERSION']
    os.environ["OPENAI_API_BASE"] = OPENAI_CONFIG['AZURE_API_BASE']
    os.environ["OPENAI_API_KEY"] = OPENAI_CONFIG['AZURE_API_KEY']
    llm = AzureChatOpenAI(
        deployment_name=OPENAI_CONFIG['AZURE_MODEL'],
        temperature=0,
        max_tokens=1024
    )
elif OPENAI_CONFIG['OPENAI_API_TYPE'] == 'openai':
    os.environ["OPENAI_API_KEY"] = OPENAI_CONFIG['OPENAI_KEY']
    llm = ChatOpenAI(
        temperature=0,
        max_tokens=1024
    )
```

Then, by running `python HELLM.py`, you can see the process of LLM making decisions using tools.

https://github.com/PJLab-ADG/DriveLikeAHuman/assets/18390668/0ec8e901-9dc1-4c89-81d6-994309a49630


![img](assets/close_loop_case_1.png)

![img](assets/close_loop_case_2.png)



## Reasoning ability with common sense

Try it with your own image in [this notebook](CaseReasoning.ipynb)!

![img](assets/reasoning_1.png)

![img](assets/reasoning_2.png)

## Performance enhancement through memorization ability

![img](assets/memorization.png)


<!-- ## Cite -->

## Acknowledgments

We would like to thank the authors and developers of the following projects, this project is built upon these great open-sourced projects.
- [highway-env](https://github.com/Farama-Foundation/HighwayEnv)
- [LangChain](https://github.com/hwchase17/langchain)
- [LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter)

## Contact

- If you have any questions, please:
  - Send email to fudaocheng@pjlab.org.cn .
  - Report issues on GitHub [Preferred] .
  - For other coorperation possibilities, please contact shibotian@pjlab.org.cn .
